Chapter Four: Distributed Transactions

The Double-Charge Problem

Imagine this scenario: A user clicks the "Buy one hundred dollar item" button. The server receives the request and charges the credit card successfully. Then the network connection drops. The server tries to respond but fails. The user doesn't see any confirmation. Confused, the user clicks the button again. The server charges the card a second time, and now two hundred dollars have been charged instead of one hundred.

This happens thousands of times daily at Stripe's scale. Distributed transactions are incredibly hard to get right.

Idempotency: The Foundation

Let's start with a critical concept. An idempotent operation is one that produces the same result regardless of how many times it's executed. Think of it this way: some operations are naturally idempotent. For example, setting a user's email address to "new at email dot com" produces the same result whether you run it once or ten times. Similarly, deleting all items from a cart for user ID 123 still results in an empty cart after ten runs.

However, not all operations are idempotent. Incrementing a counter produces different results each time: one, two, three, four, and so on. Inserting a log message into a database creates duplicates if run multiple times.

Why does idempotency matter so much? Because networks are fundamentally unreliable. Clients retry requests. Servers crash mid-operation. Without idempotency, here's what happens: the client sends a "charge one hundred dollars" request to the server. The server charges the card but crashes before responding. The client receives no response and retries. The client sends the same "charge one hundred dollars" request again. The server, now recovered, charges the card a second time. The user ends up being charged two hundred dollars and is understandably upset.

Implementing Idempotency with Keys

The solution is to implement idempotency using unique keys. Here's how it works in practice. When processing a payment, you first check if you've seen this specific request before by looking up the idempotency key. If you find an existing record, you simply return the cached result, which is exactly the same as what was returned before. If it's the first time seeing this request, you process it normally by charging the payment provider. Then you store the result for future duplicate requests, typically with a time-to-live of seventy-two hours.

The client is responsible for generating the idempotency key. On the client side, you generate a universally unique identifier, or UUID. For the first attempt, you send the request with this idempotency key in the headers. If the network fails and you need to retry, you use the same exact key. This ensures that even if the retry reaches the server, it will recognize it as a duplicate and return the original result rather than processing it again.

Idempotency Key Guidelines

Let me share some best practices for idempotency keys. The key should be generated by the client as a UUID. The scope should be per-user and per-operation type. Set a time-to-live of twenty-four to seventy-two hours, which is long enough to outlast retry storms. Store the full request and response for verification purposes. If a client tries to reuse a key with different parameters, return a 409 Conflict status code.

The Request Verification Problem

There's an important edge case to handle. What if a client reuses an idempotency key with different request parameters? For example, the first request uses key "A B C" with an amount of one hundred, and the second request reuses key "A B C" but with an amount of two hundred. These are different requests and shouldn't be treated as identical.

To handle this, when you find an existing record for an idempotency key, verify that the new request matches the original. You can do this by computing a hash of the request parameters. If the request hash doesn't match, raise a conflict error indicating that the idempotency key was reused with different parameters.

A common mistake engineers make is thinking "database transactions solve this." They don't. The failure can happen after the database transaction commits but before the client receives the response. The commit succeeded, the data is persisted, but the client doesn't know about it and will retry, potentially causing a duplicate operation.

Two-Phase Commit

Now let's talk about a different problem. Sometimes you need multiple databases or services to commit or abort together. For example, the Order Service needs to create an order in the orders database, the Payment Service needs to charge the customer in the payments database, and the Inventory Service needs to reserve items in the inventory database. All of these must succeed together, or all must roll back. Partial success creates an inconsistent state, which is unacceptable.

The Protocol

Two-Phase Commit, abbreviated as 2 P C, is a protocol designed to solve this problem. It involves a coordinator and multiple participants. In Phase One, called the Prepare phase, the coordinator sends a message to all participants saying "prepare to commit transaction T one." Each participant acquires the necessary locks, writes to its write-ahead log to ensure durability, and votes either YES, meaning it can commit, or NO, meaning it must abort. All participants send their votes back to the coordinator.

In Phase Two A, which happens if all participants voted YES, the coordinator writes "commit transaction T one" to its own write-ahead log. Then it sends a "commit" message to all participants. Each participant applies the changes and releases its locks. All participants then send confirmation back to the coordinator.

In Phase Two B, which happens if any participant voted NO, the coordinator sends an "abort" message to all participants. Each participant rolls back the changes and releases locks. All participants then confirm they have aborted.

Let me walk through the timeline visually. In Phase One, the coordinator sends the prepare message to all participants. Participant A receives the prepare message, votes YES, and sends it back. Participant B does the same. Participant C does the same. In Phase Two, assuming all voted YES, the coordinator sends the commit message to all participants. Each participant commits and sends a "done" message back.

Two-Phase Commit Problems

However, 2 P C has serious problems in practice. The first problem is blocking. Imagine this timeline: at time zero, the coordinator sends the prepare message. At time one, participants vote YES and acquire locks. At time two, the coordinator writes commit to its write-ahead log. At time three, the coordinator crashes before sending the commit message to participants. At time four, the participants are stuck. They can't commit because they haven't received the instruction. They can't abort because the coordinator might have committed. They're holding locks indefinitely, blocking other operations.

This blocking window can last until the coordinator recovers, which could be minutes or even hours in some cases.

The second problem is latency. There's a minimum of four sequential network hops for every transaction. First, the coordinator sends prepare to participants. Second, participants send their votes to the coordinator. Third, the coordinator sends commit to participants. Fourth, participants send done confirmations to the coordinator. If these services are in different data centers, each hop might take one hundred milliseconds or more, resulting in four hundred milliseconds or more per transaction.

The third problem is availability. If any participant is down, the entire transaction fails. With three participants, each with ninety-nine point nine percent availability, the probability that all are up is ninety-nine point seven percent. With ten participants, each at ninety-nine point nine percent availability, the probability that all are up drops to ninety-nine percent. More participants means lower overall availability.

When to Use Two-Phase Commit

So when should you use 2 P C? It's a good fit when you're using the same database vendor, such as distributed PostgreSQL or MySQL clusters. It's appropriate for critical financial transactions that absolutely must be atomic. It works well for low-frequency, high-value operations within a single datacenter.

On the other hand, 2 P C is a bad fit for microservices with different databases. It's inappropriate for high-throughput systems because the latency kills performance. It doesn't work well for cross-datacenter operations. And it's problematic when any participant might be slow or unreliable.

The Saga Pattern

This brings us to the Saga pattern, which takes a completely different approach. The key insight is: don't try to make distributed operations atomic. Instead, break the operation into local transactions and define compensating transactions for rollback if something goes wrong.

In the traditional ACID approach, you have one big atomic transaction that does everything: create the order, charge the payment, and reserve inventory. It's all or nothing. With the Saga pattern, you have a sequence of local transactions, each with a corresponding compensation. You create the order, then charge the card, then reserve the item. If any step fails, you run the compensations in reverse: cancel the order, refund the card, and release the item.

Saga Execution: Happy Path

Let me walk through a successful execution. Step one: create the order with status pending. Success. Step two: reserve the payment. Success. Step three: reserve the inventory. Success. Step four: confirm the order, changing status to confirmed. Success. All steps succeeded, so we're done.

Saga Execution: Failure and Compensation

Now let's see what happens when something fails. Step one: create the order with status pending. Success. Step two: reserve the payment. Success. Step three: reserve the inventory. Failure because the item is out of stock. Now compensation kicks in. Step four: refund the payment to undo step two. Success. Step five: cancel the order to undo step one. Success. The final order status is cancelled, and the user sees a message saying "item out of stock, payment refunded."

Saga Coordination Patterns

There are two main patterns for coordinating sagas: choreography and orchestration.

Pattern One: Choreography (Event-Driven)

In choreography, each service listens to events and decides what to do independently. When an order is created, the Order Service emits an "order dot created" event. The Payment Service listens for this event, processes the payment, and emits a "payment dot reserved" event. The Inventory Service listens for the payment reserved event, reserves inventory, and emits an "inventory dot reserved" event. The Order Service listens for this final event to confirm the order.

Each service handles relevant events, performs its local transaction, emits outcome events, and handles failure events by running compensation logic.

Here's how it might be implemented. In the Order Service, you have an event handler for "payment dot reserved" that updates the order status to payment reserved and saves it. You also have an event handler for "payment dot failed" that updates the order status to cancelled and emits an "order dot cancelled" event.

In the Payment Service, you have an event handler for "order dot created" that tries to reserve the payment. If successful, it emits "payment dot reserved." If it fails due to insufficient funds, it emits "payment dot failed." You also have an event handler for "inventory dot failed" that runs the compensation by refunding the payment and emitting "payment dot refunded."

Choreography has several advantages. The services are simple and decoupled. There's no single point of failure. It's easy to add new services to the flow.

However, choreography also has disadvantages. It's hard to understand the full flow because the logic is scattered across multiple services. There's no central view of the saga state. Failure handling becomes complex because it's not always clear who should compensate whom. There's also a risk of creating cyclic dependencies between services.

Pattern Two: Orchestration (Central Coordinator)

In orchestration, one service manages the entire saga. The saga orchestrator knows the full flow and manages the state machine. It explicitly calls each service in sequence: first create the order, then reserve the payment, then reserve the inventory.

Here's a simplified implementation. You define an OrderSagaOrchestrator class that contains a list of steps. Each step has an action and a compensation function. For example, step one has create order as the action and cancel order as the compensation. Step two has reserve payment as the action and refund payment as the compensation. Step three has reserve inventory as the action and release inventory as the compensation. Step four has confirm order as the action and no compensation because it's the final step.

To execute the saga, you iterate through the steps and try to execute each action. If a step succeeds, you add it to the list of completed steps. If a step fails, you run the compensation functions for all completed steps in reverse order, then raise a saga failed error.

Orchestration has several advantages. You have clear visibility into the saga state. It's easier to add or modify steps. Error handling is centralized. It works better for complex business logic.

The disadvantages are that the orchestrator becomes a potential single point of failure. It can become a bottleneck for high-throughput systems. Services are more tightly coupled to the orchestrator. And you have more infrastructure to manage.

Designing Compensating Transactions

Compensating transactions must meet several requirements.

First, they must be idempotent, meaning safe to retry. For example, in a refund payment function, you first check if the payment status is already "refunded." If it is, you simply return because the work is already done. This makes the operation idempotent. If it hasn't been refunded yet, you call the payment provider to issue the refund, update the status to "refunded," and save it.

Second, compensating transactions should be commutative, meaning the order shouldn't matter. If a refund and an inventory release happen concurrently, the final state should be the same regardless of which completes first.

Third, compensations may be eventual, meaning they may take time to complete. Compensation might involve external APIs that are slow, manual intervention that could take days, or batch processes that run on a schedule.

Semantic versus Physical Compensation

There are two types of compensation. Physical compensation means undoing the exact operation. Charging one hundred dollars is compensated by refunding one hundred dollars. Reserving five items is compensated by unreserving five items.

Semantic compensation means a business-level undo. Creating a shipment is compensated by canceling the shipment, which might be a different API and might incur fees. Sending an email can't be unsent, so you send a follow-up email saying "oops, ignore that." Generating a report is compensated by marking the report as invalid. Publishing an article is compensated by publishing a retraction.

Physical compensation is simpler but not always possible. You should design for semantic compensation from the start when building saga-based systems.

Saga State Management

Managing saga state properly is critical. You can think of saga execution as a state machine. It starts in the "started" state, transitions to "order created," then either moves to "payment reserved" on success or "payment failed" on failure. From payment reserved, it moves to "inventory reserved," and finally to "completed." If payment failed, it moves to "compensating" and then to "failed."

You need to persist the saga state in a database. Create a saga state table with columns for saga ID, saga type, current step, state, payload stored as JSON, created timestamp, and updated timestamp. Also create a saga step log table that tracks each step's execution, including the saga ID, step number, step name, action status, compensation status, error message if any, and execution timestamp.

Why persist saga state? First, for recovery after a crash. Second, for debugging and auditing. Third, to retry stuck sagas. Fourth, to monitor saga health and alert when things go wrong.

Handling the "In-Between" State

Sagas have windows where the system is temporarily inconsistent. At time zero, the order is created in the Order service. At time one, payment is still processing, but the user might see the order without confirmed payment. At time two, payment is confirmed. At time three, inventory is still being reserved, so payment is done but inventory isn't reserved yet. At time four, the saga is complete.

There are several solutions to handle this inconsistent window. First, show a "processing" status to users. Return a response with the order ID, status set to "processing," and a message saying "your order is being confirmed." This way users see a clear state instead of a confusing partial state.

Second, use eventual confirmation. Immediately show a message saying "order received, confirmation coming soon." Later, send an email or notification when the saga completes. This sets user expectations correctly.

Third, implement timeout and retry logic. You can have a background job that checks for stuck sagas by querying for sagas in processing state that haven't been updated in the last five minutes. For each stuck saga, if the retry count is below the maximum, retry the saga. Otherwise, escalate to a human for manual intervention.

Try-Confirm-Cancel

Try-Confirm-Cancel, or T C C, is a variation of the Saga pattern specifically designed for resource reservation scenarios. It has three phases.

In the Try phase, you reserve resources tentatively. You create a soft lock on inventory, you authorize the payment without capturing it, and you create a pending order.

In the Confirm phase, which happens if all Try operations succeeded, you finalize everything. You consume the reserved inventory, capture the payment, and confirm the order.

In the Cancel phase, which happens if any Try operation failed, you release all reservations. You release the inventory lock, void the payment authorization, and cancel the order.

The advantage of T C C over a regular Saga is that resources are reserved upfront, which reduces compensation complexity. The disadvantage is that it requires all services to support the Try, Confirm, Cancel pattern, which is more complex to implement.

Distributed Transaction Patterns Comparison

Let me compare the different patterns. Two-Phase Commit provides strong ACID consistency but has low availability and medium complexity. It's best for scenarios using the same database vendor and critical transactions.

Saga with choreography provides eventual consistency with high availability and medium complexity. It's good for simple flows and microservices.

Saga with orchestration also provides eventual consistency with high availability but has higher complexity. It's best when you have complex flows and need visibility into the process.

Try-Confirm-Cancel provides strong-ish consistency with medium availability and high complexity. It's specifically designed for resource reservation scenarios.

Key Concepts Checklist

Let me summarize the key concepts you should master. First, identify whether you actually need a distributed transaction at all. Second, design idempotent operations using idempotency keys. Third, choose between Two-Phase Commit and Saga based on your requirements. Fourth, design compensating transactions for each step. Fifth, handle the "in-between" inconsistent state appropriately. Sixth, consider timeout and retry strategies. Seventh, plan for partial failures and manual intervention.

Practical Insights

Here are some practical insights from building distributed systems in production.

First, avoid distributed transactions when possible. Ask yourself: can you redesign the system to avoid cross-service transactions entirely? Can you use eventual consistency with periodic reconciliation? Can you batch operations to reduce transaction overhead?

Second, saga debugging is incredibly hard. You must log every step with a correlation ID that spans all services. Store the full request and response payloads for each step. Build an admin user interface to view saga state visually. Set up alerts for stuck sagas that haven't progressed in a reasonable time.

Third, remember that compensation is business logic, not just technical rollback. Compensation isn't just about reverting database changes. It may involve customer communication, such as sending an apology email. It may have financial implications, such as refund processing fees. Design compensation strategies together with your product team, not just the engineering team, to ensure you're handling the business implications correctly.

That concludes Chapter Four on Distributed Transactions.